from tqdm import tqdm
from eldar import build_query
from nltk.tokenize import sent_tokenize

from summarisation import _extract_summaries


def extract(data, method, **kwargs):
    """Calls extraction method.

    Extraction method is expected to take a pandas.DataFrame object for the
    review data, with the 'text' field representing the review data. The method
    should return a pandas.DataFrame object in the same format
    (i.e. same columns - asin, id, etc) but with an additional 'extraction'
    column representing the extracted text.

    If the method generates multiple
    extraction per review, then there should be a new row for each of these
    extractions, with the remaining fields duplicated for that review."""

    func = globals()[method]
    return func(data, **kwargs)


def extract_reviews(data, query=""):
    """Simply 'extract' the full reviews. These can be filtered using keywords
    queries if desired."""
    reviews = []
    idxs = []
    for i, review in enumerate(data.text):
        if any(word.strip().lower() in review.lower() for word in query.split(",")):
            reviews.append(review)
            idxs.append(i)
    data = data.iloc[idxs].copy()
    data["extraction"] = reviews
    data.drop_duplicates(subset=["id", "extraction"])
    return data


def extract_sentences(data, eldar=False, query=""):
    """Extract sentencs from the reviews. These can be filtered using keywords
    queries if desired."""

    if not eldar:
        idxs = []
        sentences = []
        for i, review in enumerate(data.text):
            sents = sent_tokenize(review)
            for sent in sents:
                if any(
                    word.strip().lower() in sent.lower() for word in query.split(",")
                ):
                    sentences.append(sent)
                    idxs.append(i)
        data = data.iloc[idxs].copy()
        data["extraction"] = sentences
    else:
        idxs = []
        sentences = []
        cleaned_query = (
            query.replace("*", "")
            .replace("|", "OR")
            .replace("+", "AND")
            .replace("-", "AND NOT")
        )
        keyword_query = build_query(cleaned_query)
        for i, review in enumerate(data.text):
            sents = sent_tokenize(review)
            for sent in sents:
                match = keyword_query.filter([sent])
                if len(match) > 0:
                    sentences.append(sent)
                    idxs.append(i)
        data = data.iloc[idxs].copy()
        data["extraction"] = sentences
    # Drop modified text if it is repeated in the same review
    return data


def extract_summaries(data, **kwargs):
    """Wrapper for the extract_summaries method"""
    data = _extract_summaries(data, **kwargs)
    return data
