"""A script for hierarchical clustering, exporting output as a D3 dendrogram

Args:
    file (str): File containing text for embedding.
    extraction_method (str): Method for extracting struggles.
    label (str): 'struggle' or 'substruggle'. Defaults to 'substruggle'.
    embedding_score_method (str): Method for evaluating embeddings.
        Defaults to 'knn_dendrogram_score'.
    clustering_score_method (str): Method for evaluating dendrogram.
        Defaults to 'f1_dendrogram_score'.
    tf_hub_model (str): URL for tensorflow hub model.
        Defaults to 'https://tfhub.dev/google/universal-sentence-encoder-large/4'.
    embed_batch_size (int): Embedding batch size. Defaults to 100.
    linkage_method (str): Method used to calculate distance between clusters. Defaults to ward.
    linkage_metric (str): Distance metric used. Defaults to euclidean.
"""
# Imports for evaluation pipeline.
import sys
sys.path.append('../sentence_dendrogram')

import os
import json
import argparse
import extraction
import evaluation
import filtering
import pandas as pd

from pprint import pprint
from evaluation import extraction_stats
from preprocessing import embed_text
from postprocessing import save
from labelling import label_extractions
from tree import create_tree

# Setting up Sacred experiment.
import ssl
from setup import get_secret
from sacred import Experiment
from sacred.observers import MongoObserver

ex = Experiment()
secret = get_secret("sacred_mongo_credentials")
ex.observers.append(MongoObserver(
    url=f"mongodb+srv://{secret['username']}:{secret['password']}@sacred-k4oew.mongodb.net",
    username=secret["username"],
    password=secret["password"],
    db_name="sacred",
    ssl_cert_reqs=ssl.CERT_NONE)
    )


@ex.config
def cfg():
    # file = None
    file = "s3://klydo-data-acquisition/reviews/curated/csv/hair_loss_v4_sentences.csv"
    extraction_method = "extract_sentences"
    filtering_method = "length_filter"
    min_extraction_len = 5
    label = "substruggle"
    embedding_score_method = "knn_embedding_score"
    clustering_score_method = "f1_dendrogram_score"
    tf_hub_model = "https://tfhub.dev/google/universal-sentence-encoder-large/4"
    embed_batch_size = 100
    linkage_method = "ward"
    linkage_metric = "euclidean"

@ex.capture
@ex.automain
def main(file,
         extraction_method,
         filtering_method,
         min_extraction_len,
         label,
         embedding_score_method,
         clustering_score_method,
         tf_hub_model,
         embed_batch_size,
         linkage_method,
         linkage_metric):

    print("\nLoading data...")
    labelled_data = pd.read_csv(file)

    # Create dataframe of just the reviews for extraction. This is then compared
    # to the gold standard sentence extractions.
    data = (labelled_data.drop_duplicates(subset=["text"])
                         .drop(columns=["sentence", "struggle", "substruggle"])
            )

    print("\nExtracting data...")
    data = getattr(extraction, extraction_method)(data)

    print("\nNoise filtering data...")
    data = getattr(filtering, filtering_method)(data, min_extraction_len)

    print("\nLabelling data...")

    data = label_extractions(data, labelled_data[["sentence", label]].values)
    extract_stats = extraction_stats(data, labelled_data)
    extraction_scores = dict(zip(["n_extractions", "precision", 
                                  "recall", "f1", "n_labels_per_extraction"],
                                  extract_stats))

    print("\nEmbedding data...")
    embeddings = embed_text(
        data["extraction"], tf_hub_model, embed_batch_size
    )
    embedding_eval_method = getattr(evaluation, embedding_score_method)
    embedding_score = embedding_eval_method(embeddings, data["label"].values)

    tree, rootnode = create_tree(
        embeddings,
        linkage_method,
        linkage_metric,
        1000,
        5,
        data[["extraction", "id", "asin"]],
        "dist",
    )
    clustering_eval_method = getattr(evaluation, clustering_score_method)
    cluster_gt_score = clustering_eval_method(G=tree, label_data=data, gt_data=labelled_data, gt_label=label)
    cluster_score = clustering_eval_method(G=tree, label_data=data)
    output = save(tree, data)
    
    with open("pipeline_output.txt", "w") as f:
        f.writelines("\n".join(output))
    ex.add_artifact("pipeline_output.txt")
    os.remove("pipeline_output.txt")

    # Log data to sacred experiment
    with open("extraction_scores.json", "w+") as f:
        json.dump(extraction_scores, f, indent=2)
    ex.add_artifact("extraction_scores.json")
    os.remove("extraction_scores.json")

    with open("embedding_scores.json", "w+") as f:
        json.dump(embedding_score, f, indent=2)
    ex.add_artifact("embedding_scores.json")
    os.remove("embedding_scores.json")

    with open("clustering_scores.json", "w+") as f:
        json.dump(cluster_score, f, indent=2)
    ex.add_artifact("clustering_scores.json")
    os.remove("clustering_scores.json")

    with open("clustering_gt_scores.json", "w+") as f:
        json.dump(cluster_gt_score, f, indent=2)
    ex.add_artifact("clustering_gt_scores.json")
    os.remove("clustering_gt_scores.json")

    ex.log_scalar("extraction recall", extraction_scores["recall"])
    ex.log_scalar("extraction precision", extraction_scores["precision"])
    ex.log_scalar("cluster f1", cluster_score["overall"][2])
    ex.log_scalar("cluster precision", cluster_score["overall"][0])
    ex.log_scalar("cluster recall", cluster_score["overall"][1])

    print(f"\nDone!")
    print(f"\nExtraction score:")
    pprint(extraction_scores)
    print(f"\nEmbedding score:")
    pprint(embedding_score)
    print(f"\nClustering score:")
    pprint(cluster_score)
    print("\nClustering GT score:")
    pprint(cluster_gt_score)
