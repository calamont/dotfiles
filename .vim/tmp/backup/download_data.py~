"""A quick script for downloading the data from elasticsearch."""
import os
import re
import ast
import glob
import json
import klydo
import argparse
import pandas as pd

parser = argparse.ArgumentParser()
parser.add_argument("file", type=str, help=".json file of report reviews.")
parser.add_argument("save_file", type=str, help="File to save .csv as.")
args = parser.parse_args()

with open(args.file, "r") as f:
    struggles = json.load(f)

dicts = []
for struggle, substruggles in struggles.items():
    for substruggle, reviews in substruggles.items():
        for review_id in reviews:
            try:
                review = klydo.s3.object.get(
                            bucket="klydo-data-acquisition", 
                            key="reviews/amazon/" + review_id,
                            decode="utf-8"
                            )
            except:
                print(f"Couldn't download {review_id}")
                continue
            review = re.sub(r"\\u\w\w\w+", "", review)  # get rid of unicode surrogates
            review = ast.literal_eval(review)
            review["struggle"] = struggle
            review["substruggle"] = substruggle
            dicts.append(review)
df = pd.DataFrame(dicts)
df.to_csv(args.save_file, encoding="utf-8")
