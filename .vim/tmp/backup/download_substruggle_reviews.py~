"""A quick script for downloading the data from elasticsearch."""
import os
import re
import ast
import glob
import json
import klydo
import argparse
import pandas as pd

parser = argparse.ArgumentParser()
parser.add_argument("file", type=str, help=".json file of report reviews.")
parser.add_argument("save_file", type=str, help="File to save .csv as.")
args = parser.parse_args()

with open(args.file, "r") as f:
    substruggles = json.load(f)

dicts = []
for substruggle, reviews in substruggles.items():
    for review_id in reviews:
        try:
            review = klydo.s3.object.get(
                        bucket="klydo-data-acquisition", 
                        key="reviews/amazon/" + review_id,
                        decode="utf-8"
                        )
        except:
            print(f"Couldn't download {review_id}")
            continue
        review = re.sub(r"\\u\w\w\w+", "", review)  # get rid of unicode surrogates
        review = ast.literal_eval(review)
        review["label"] = substruggle
        dicts.append(review)
df = pd.DataFrame(dicts)
# Drop duplicate reviews in with the same label.
df = df.drop_duplicates(subset=["asin", "id", "text", "label"])
df.to_csv(args.save_file, encoding="utf-8")
