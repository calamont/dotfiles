import re
import json
import argparse
import pandas as pd
from klydo import s3
from eldar import build_query
from nltk import tokenize

parser = argparse.ArgumentParser()
parser.add_argument("curated_csv", type=str, help="CSV file of curated reviews.")
parser.add_argument("query", type=str, help="File with class->query mappings.")
parser.add_argument("save_file", type=str, help="File to save updated CSV as.")
args = parser.parse_args()

with open(args.query, "r") as f:
    queries = json.load(f)

reviews = pd.read_csv(args.curated_csv)

df_sentences = []
for row in reviews.itertuples(index=False):
    try:
        query = queries[row.substruggle]
    except KeyError:
        continue
    single_word = re.match(r"^\((\w+)\*?\)$", query)
    if single_word is not None:  # eldar doesn't work with (query*) fron ES
        cleaned_query = single_word.group(1)
    else:
        cleaned_query = query.replace("*", "").replace("|", "OR").replace("+", "AND")
    keyword_query = build_query(cleaned_query)
    sentences = tokenize.sent_tokenize(row.text)
    matching_sentences = keyword_query.filter(sentences)
    for sentence in matching_sentences:
        d = row._asdict()
        d["sentence"] = sentence
        df_sentences.append(d)
df = pd.DataFrame(df_sentences)
df.to_csv(args.save_file)
